import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import seaborn as sns # Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics
import matplotlib.pyplot as plt # collection of functions that make matplotlib work like MATLAB

%matplotlib inline 
from sklearn.preprocessing import LabelEncoder # Encode target labels with values between 0 and n_classes-1.
import warnings
warnings.filterwarnings('ignore') #to ignore deprecation warnings

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Importing data into variables
training_set = pd.read_csv('../input/airline-passenger-satisfaction/train.csv')
test_set = pd.read_csv('../input/airline-passenger-satisfaction/test.csv')

# Row and column count of training and test sets
print("Shape of train dataset:  ",training_set.shape )
print("Shape of test dataset:  ",test_set.shape )
 # Getting the first 10 data from training set 
training_set.head(10)

# Data Preparation
# Getting rid of the unnecessary columns in both training and test sets
training_set.drop(labels = ['Unnamed: 0', 'id'], axis = 1, inplace= True)
test_set.drop(labels = ['Unnamed: 0', 'id'], axis = 1, inplace= True)

dataset = training_set.append(test_set)

# Getting more details regarding data
# Print a concise summary of a DataFrame
# To get a quick overview of the dataset 
dataset.info()

#find categorical data
categorical_data = training_set.select_dtypes(exclude= np.number)
categorical_col = categorical_data.columns
categorical_data.head(10)

# Find categorical data 'object'
# Convert categorical data to numeric
lencoders = {}
for col in training_set.select_dtypes(include=['object']).columns: # select the columns that include 'object'
    lencoders[col] = LabelEncoder() # used to transform non-numerical labels
    training_set[col] = lencoders[col].fit_transform(training_set[col]) #do a calculation and fitting data on the training set

lencoders = {}
for col in test_set.select_dtypes(include=['object']).columns: # select the columns that include 'object'
    lencoders[col] = LabelEncoder() # used to transform non-numerical labels
    test_set[col] = lencoders[col].fit_transform(test_set[col]) #do a calculation and fitting data on the training set

training_set.head(10)

# Checking if there is any null value
training_set.isnull().sum()

# Replacing null values with the mean of the column
training_set['Arrival Delay in Minutes'].fillna((training_set['Arrival Delay in Minutes'].mean()), inplace=True)

test_set['Arrival Delay in Minutes'].fillna((test_set['Arrival Delay in Minutes'].mean()), inplace=True)

features = ['Gender','Customer Type', 'Age', 'Type of Travel', 'Class',
       'Flight Distance', 'Inflight wifi service',
       'Departure/Arrival time convenient', 'Ease of Online booking',
       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',
       'Inflight entertainment', 'On-board service', 'Leg room service',
       'Baggage handling', 'Checkin service', 'Inflight service',
       'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']
target = ['satisfaction']

# Split into test and train
X_train = training_set[features]
y_train = training_set[target].to_numpy()
X_test = test_set[features]
y_test = test_set[target].to_numpy()

X_test.head()

dataset = training_set.append(test_set)
training_set.isnull().sum()

training_set.describe() # calculating some statistical data like percentice, mean and std of the numerical values of DataFrame

numeric =['Gender',	'Customer Type',	'Type of Travel',	'Class',	'satisfaction']

for count in numeric:
  print("{} \n".format(training_set[count].value_counts())) # formats the specified value(s) and insert them inside the string's placeholder. The placeholder is defined using curly brackets: {}.

# 0- Female, 1- Male
colors = ['#ff9999','#66b3ff']
ax_worktype2=training_set['Gender'].value_counts().plot(kind='pie', rot=0, title='Gender Ratio', colors = colors,autopct='%1.1f%%')

# 0- Loyal Customer, 1- Disloyal Customer
training_set['Customer Type'].value_counts().plot(kind='bar', rot=0, title='Histogram of Customer Type')

plt.figure(figsize = (8, 5))
age_hist = sns.distplot(training_set['Age'], color = 'blue')
plt.ylabel('Density', size = 12)
plt.xlabel('Age', size = 14)

# 0- Business Travel, 1- Personal Travel
training_set['Type of Travel'].value_counts().plot(kind='bar', rot=0, title='Histogram of Type of Travel')

# 0- Business, 1- Eco, 2- Eco Plus
# People travel more via Eco rather than Eco Plus
training_set['Class'].value_counts().plot(kind='bar', rot=0, title='Histogram of Class')

# 0- neutral/dissatisfied, 1- satisfied
print('People are more neutral/dissatisfied than satisfied with the airline')
training_set['satisfaction'].value_counts().plot(kind='bar', rot=0, title='Histogram of Satisfaction', color = ['salmon','#66b3ff'])
print('How many people satisfacted by Airline service: ')
training_set.groupby('Gender')[['satisfaction']].sum()

print('Percentage of satisfacted people : ')
training_set.groupby('Gender')[['satisfaction']].sum()/ training_set.groupby('Gender')[['satisfaction']].count()

# 0- Female, 1 - Male,  0- Dissatisfaction, 1-satisfaction
plt.figure(figsize = (10,10))
plt.subplot(2,2,1)
sns.countplot(data = training_set, x="Gender" , hue="satisfaction", palette="cool")
plt.title("Histogram of Satisfaction Across Gender")
plt.legend()

# 0- Business, 1- Eco, 2- Eco Plus 
print('Satisfaction of people depending on the class: ')
training_set.groupby('Class')[['satisfaction']].sum()

# 0- Business, 1- Eco, 2- Eco Plus
print('Number of people for each class:')
training_set.groupby('Class')[['satisfaction']].count()

# 0- Business, 1- Eco, 2- Eco Plus
print('Percentage of satisfacted people depending from the class:')
training_set.groupby('Class')[['satisfaction']].sum()/ training_set.groupby('Class')[['satisfaction']].count()

# 0- Business, 1 - Eco, 2- Eco Plus
plt.figure(figsize = (10,10))
plt.subplot(2,2,1) #  which creates a single subplot within a grid. As you can see, this command takes three integer argumentsâ€”the number of rows, the number of columns, and the index of the plot to be created in this scheme
sns.countplot(data = training_set, x="Class" , hue="satisfaction", palette="cool") # countplot method is used to Show the counts of observations in each categorical bin using bars.
plt.title("Histogram of Satisfaction Across Class")
plt.legend() # legend is an area describing the elements of the graph

# 0-Business Travel, 1- Personal Travel
print('Percentage of satisfacted people depending from the type of travel:')
training_set.groupby('Type of Travel')[['satisfaction']].sum()/ training_set.groupby('Type of Travel')[['satisfaction']].count()

# 0-Business Travel, 1- Personal Travel
plt.figure(figsize = (10,10))
plt.subplot(2,2,1)
sns.countplot(data = training_set, x="Type of Travel" , hue="satisfaction", palette="cool")
plt.title("Histogram of Satisfaction Across Type of Travel")
plt.legend()

print('Percentage of satisfacted people depending from the customer type:')
training_set.groupby('Customer Type')[['satisfaction']].sum()/ training_set.groupby('Type of Travel')[['satisfaction']].count()

# 0- Loyal Customer, 1- Disloyal customer
plt.figure(figsize = (10,10))
plt.subplot(2,2,1)
sns.countplot(data = training_set, x="Customer Type" , hue="satisfaction", palette="cool")
plt.title("Histogram of Satisfaction Across Customer Type")
plt.legend()

plt.figure(figsize = (8, 5))
fligth_dist_hist = sns.distplot(training_set['Flight Distance'], color = 'blue')
plt.ylabel('Frequency', size = 8)
plt.xlabel('Flight Distance', size = 14)

plt.figure(figsize = (8, 5))
fligth_dist_hist = sns.distplot(training_set['Departure Delay in Minutes'], color = 'blue')
plt.ylabel('Density', size = 12)
plt.xlabel('Departure Delay in Minutes', size = 14)

plt.figure(figsize = (8, 5))
fligth_dist_hist = sns.distplot(training_set['Arrival Delay in Minutes'], color = 'blue')
plt.ylabel('Density', size = 12)
plt.xlabel('Arrival Delay in Minutes', size = 14)

# kdeplot method for visualizing the distribution of observations in a dataset,
plt.figure(figsize=(10,10))
plt.subplot(2,2,1)

sns.kdeplot(training_set.loc[training_set["satisfaction"]==1]["Age"],alpha=0.5,label="satisfaction")
sns.kdeplot(training_set.loc[training_set["satisfaction"]==0]["Age"],alpha=0.5,label="neutral or dissatisfied")
plt.title("Satisfaction vs Age")
plt.legend()

plt.figure(figsize=(8, 5))
age_satisfaction = sns.distplot(training_set[training_set['satisfaction']==1]['Age'],color='red')
plt.ylabel('Density',size=14)
plt.xlabel('Age',size=14)

def bar_plot(variable):
  var = training_set[variable]
  var_value= var.value_counts()

  plt.figure(figsize= (9,3))
  plt.bar(var_value.index, var_value.values)
  
  plt.xlabel("Passengers score")
  plt.ylabel("Frequency")
  plt.title(variable)
  plt.show() 

  print("{}: \n {}".format(variable,var_value))


category1 = [ "Inflight wifi service", "Departure/Arrival time convenient", "Ease of Online booking", "Gate location", "Food and drink", "Online boarding", "Seat comfort", "Inflight entertainment", "On-board service", "Leg room service", "Baggage handling", "Checkin service", "Inflight service", "Cleanliness",]

for name in category1:
  bar_plot(name)

def bar_plot(variable):
  var = training_set[variable]
  var_value= var.value_counts()
  sns.countplot(data=training_set, x= training_set[variable] , hue="satisfaction", palette="cool")
  
  plt.xlabel("Passengers score")
  plt.ylabel("Frequency")
  plt.title(variable)
  plt.show() 

  print("{}: \n {}".format(variable,var_value))

category1 = [ "Inflight wifi service", "Departure/Arrival time convenient", "Ease of Online booking", "Gate location", "Food and drink", "Online boarding", "Seat comfort", "Inflight entertainment", "On-board service", "Leg room service", "Baggage handling", "Checkin service", "Inflight service", "Cleanliness", "Arrival Delay in Minutes", "Departure Delay in Minutes", "Flight Distance"]

for name in category1:
  bar_plot(name)

#Plotting the correlation coefficients of all the Features
#training_set.corr() - Pearson Correlation Coefficients
plt.figure(figsize=(18,12))
sns.heatmap(training_set.corr(),vmin=-1, vmax=1, annot=True,cmap='PuOr')

plt.figure(figsize=(16,10))
# define the mask to set the values in the upper triangle to True
mask = np.triu(np.ones_like(dataset.corr(), dtype=np.bool))
heatmap = sns.heatmap(dataset.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='PuOr')
heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':18}, pad=16);
plt.figure(figsize=(8, 12))
heatmap = sns.heatmap(training_set.corr()[['satisfaction']].sort_values(by='satisfaction', ascending=False), vmin=-1, vmax=1, annot=True, cmap='PuOr')
heatmap.set_title('Features Correlating with satisfaction', fontdict={'fontsize':18}, pad=16);

X_train.shape, y_train.shape

X_test.shape, y_test.shape

# **Build the Classification Algorithms**

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, plot_confusion_matrix
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
import sklearn.metrics as metrics
import time

def classAlg(model):
    t0=time.time()
    
    model.fit(X_train,y_train)
    prediction_test = model.predict(X_test)

    print('Classification Data Test')
    print(classification_report(y_test,prediction_test, digits=5))
    accuracy = accuracy_score(y_test, prediction_test)
    roc_auc = roc_auc_score(y_test, prediction_test)
    time_taken = time.time()-t0
    print("Accuracy = {}".format(accuracy))
    print("ROC Area under Curve = {}".format(roc_auc))
    print("Time taken = {}".format(time_taken))
    print("----------------------------------------------")
    print('True', y_test[0:21])
    print('Pred', prediction_test[0:21])
    print("----------------------------------------------")
    print("First argument is true values, second argument is predicted values")
    print(metrics.confusion_matrix(y_test, prediction_test))
    
    return model, accuracy, roc_auc, time_taken

def models_result(model, X_test, y_test):
    labels = model.predict(X_test)
    matrix = confusion_matrix(y_test, labels)
    ax = sns.heatmap(matrix.T, square=True, annot=True, fmt='d', cbar=False)
    ax.set(xlabel='predicted values',ylabel='true values')
    ax.set_xticklabels(['neutral/dissatisfied', 'satisfied'])
    ax.set_yticklabels(['neutral/dissatisfied', 'satisfied', ])

model_RF = RandomForestClassifier()
model_rf, accuracy_rf, roc_auc_rf, tt_rf= classAlg(model_RF) 
models_result(model_RF, X_test, y_test)

plot_confusion_matrix(model_RF, X_test, y_test,cmap=plt.cm.Blues, normalize = 'all')

model_LR = LogisticRegression()
model_lr, accuracy_lr, roc_auc_lr, tt_lr= classAlg(model_LR) 
models_result(model_LR, X_test, y_test)
plot_confusion_matrix(model_LR, X_test, y_test,cmap=plt.cm.Blues, normalize = 'all')

model_TREE = DecisionTreeClassifier()
model_dt, accuracy_dt, roc_auc_dt, tt_dt= classAlg(model_TREE) 
models_result(model_TREE, X_test, y_test)

plot_confusion_matrix(model_TREE, X_test, y_test,cmap=plt.cm.Blues, normalize = 'all')

model_GBM = GradientBoostingClassifier()
model_gb, accuracy_gb, roc_auc_gb, tt_gb= classAlg(model_GBM) 
models_result(model_GBM, X_test, y_test)

plot_confusion_matrix(model_GBM, X_test, y_test,cmap=plt.cm.Blues, normalize = 'all')

model_KNN = KNeighborsClassifier()
model_kn, accuracy_kn, roc_auc_kn, tt_kn= classAlg(model_KNN) 
models_result(model_KNN, X_test, y_test)

plot_confusion_matrix(model_KNN, X_test, y_test,cmap=plt.cm.Blues, normalize = 'all')

model_GNB = GaussianNB()
model_nb, accuracy_nb, roc_auc_nb, tt_nb= classAlg(model_GNB) 
models_result(model_GNB, X_test, y_test)

plot_confusion_matrix(model_GNB, X_test, y_test,cmap=plt.cm.Blues, normalize = 'all')

import lightgbm as lgb
model_LGB = lgb.LGBMClassifier()
model_lb, accuracy_lb, roc_auc_lb, tt_lb= classAlg(model_LGB)
models_result(model_LGB, X_test, y_test)

plot_confusion_matrix(model_LGB, X_test, y_test,cmap=plt.cm.Blues, normalize = 'all')

#partioning the independent and dependent data
X=training_set.drop('satisfaction',axis=1)
y=training_set['satisfaction']

#Univariate Feature Selection
from sklearn.feature_selection import mutual_info_classif
mic=mutual_info_classif(X,y)

mic=pd.Series(mic)
mic.index=X.columns
mic.sort_values(ascending=False)

roc_auc_scores = [roc_auc_rf, roc_auc_lr, roc_auc_dt, roc_auc_gb,  roc_auc_kn, roc_auc_nb, roc_auc_lb]
accuracy_score = [accuracy_rf, accuracy_lr, accuracy_dt, accuracy_gb,  accuracy_kn, accuracy_nb, accuracy_lb]
classifiers=['Random Forest','Logistic Regression','Decision Tree','Gradient Boosting','K-NN','Naive Bayes','LightGBM']
model_scores_auc = pd.DataFrame(roc_auc_scores, index=classifiers, columns=['AUC'])
model_scores_auc.sort_values(by='AUC',ascending=False).head(7)

model_scores_acc = pd.DataFrame(accuracy_score, index=classifiers, columns=['Accuracy'])
model_scores_acc.sort_values(by='Accuracy',ascending=False).head(7)
roc_auc_scores = [roc_auc_rf, roc_auc_lr, roc_auc_dt, roc_auc_gb,  roc_auc_kn, roc_auc_nb, roc_auc_lb]
tt = [tt_rf, tt_lr, tt_dt, tt_gb, tt_kn, tt_nb, tt_lb]
model_data = {'Model': ['Random Forest','Logistic Regression','Decision Tree','Gradient Boosting','K-NN','Naive Bayes','LightGBM'],
              'ROC_AUC': roc_auc_scores,
              'Time taken': tt}
data = pd.DataFrame(model_data)

fig, ax1 = plt.subplots(figsize=(14,8))
ax1.set_title('Model Comparison: Area under ROC Curve and Time taken for execution by Various Models', fontsize=13)
color = 'tab:blue'
ax1.set_xlabel('Model', fontsize=13)
ax1.set_ylabel('Time taken', fontsize=13, color=color)
ax2 = sns.barplot(x='Model', y='Time taken', data = data, palette='Blues_r')
ax1.tick_params(axis='y')
ax2 = ax1.twinx()
color = 'tab:orange'
ax2.set_ylabel('ROC_AUC', fontsize=13, color=color)
ax2 = sns.lineplot(x='Model', y='ROC_AUC', data = data, sort=False, color=color)
ax2.tick_params(axis='y', color=color)
